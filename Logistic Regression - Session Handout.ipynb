{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression - Session Handout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this session we take a deep dive into Logistic Regression. The technical term for this technique is a *generalised linear model*, and is something apprenitces should be familiar with using on the L4 Data Analyst course. Traditionally (prior to v1.5 cohorts) this technique has not been delivered to learners in detail.  \n",
    "\n",
    "Below is a summary of how Logistic Regression classifiers are built upon but differ from the normal linear model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that for any binary classification task we are after outputs of $0\\leq h_{\\theta}(x) \\leq 1$ for whatever model we construct. \n",
    "\n",
    "To model our logistic regression, we will take the original linear regression model <br><br>\n",
    "\n",
    "<center>$h_{\\theta}(x) = \\theta^{T}x$</center>\n",
    "\n",
    "and amend it by the addition of a new parameter $g$ to give <br><br>\n",
    "\n",
    "<center>$h_{\\theta}(x) = g(\\theta^{T}x$) </center>  <br><br>\n",
    "\n",
    "<center>where $g_{z} = \\frac{1}{1+\\exp^{-z}}$</center>\n",
    "\n",
    "This is known as the **Sigmoid** or **Logistic function.** Our model (hypothesis) then becomes: <br><br>\n",
    "\n",
    "<center> $h_{\\theta}(x) = \\frac{1}{1+\\exp^{-{\\theta}^T x}}$</center> \n",
    "\n",
    "This function is plotted below. Note how at high and low $x$ the sigmoid satifies our output requirement of $0\\leq h_{\\theta}(x) \\leq 1$. Wrapping our normal linear model in this function allows our model to make linear fits, but limits the maximum and minimum output values. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(-10, 10, 100) \n",
    "z = 1/(1 + np.exp(-x)) \n",
    "  \n",
    "plt.plot(x, z) \n",
    "plt.xlabel(\"x\") \n",
    "plt.ylabel(\"Sigmoid(X)\") \n",
    "  \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We interpret the output of our model as <br><br>\n",
    "<center> $h_{\\theta}(x) = P(y=1|x;\\theta)$</center> <br>\n",
    "Or in words: the probability that y=1, given x, parameterised by $\\theta$. Similarly then, for a binary classification problem:<br><br>\n",
    "<center> $P(y=0|x;\\theta) = 1 - P(y=1|x;\\theta)$</center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Like in normal linear regression, we can generate non-linear models using logistic regresssion. To do so, we would need to use some higher order non-linear terms within our hypothesis <br><br>\n",
    "\n",
    "<center>$h_{\\theta}(x) = g(\\theta_{0} + \\theta_{1}x_{1} + \\theta_{2}x_{2} +.  \\theta_{3}x_{1}^{2} +  \\theta_{4}x_{2}^{2}$) </center>  <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In linear regression we use **Mean Squared Error** cost function to penalise our model during training: <br><br>\n",
    "\n",
    "<center>$J(\\theta) = \\frac{1}{2m}{\\sum^{m}_{i=1}{Cost}(h_{\\theta}(x^{(i)}),y^{(i)}))}$</center> <br>\n",
    "\n",
    "where\n",
    "\n",
    "<center>$\\textrm{Cost}(h_{\\theta}(x),y)= (h_{\\theta}(x^{(i)})-y^{(i)})^{2},$</center> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, inputting our new hypothesis (Logistic Regression model) defined above<br><br><br>\n",
    "\n",
    "<center> $h_{\\theta}(x) = \\frac{1}{1+\\exp^{-{\\theta}^T x}}$</center> <br>\n",
    "\n",
    "creates a non-convex $J(\\theta)$. The mathematical detail of this are beyond the scope of this session, but essentially this means we need a new cost function to train our model on!\n",
    "\n",
    "Or new cost function will intead be: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>$\\textrm{Cost}(h_{\\theta}(x),y)=   \\begin{cases}\n",
    "    -\\log(h_{\\theta}(x))       & \\quad \\text{if } y=1\\\\\n",
    "    -\\log(1-h_\\theta(x))  & \\quad \\text{if } y=0 \n",
    "  \\end{cases}$<br><br>\n",
    "    \n",
    "Known as the **log-loss** or **cross-entropy** loss function. For more information see this [link](https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html#cross-entropy). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An equivelent and more compact of writing this is: <br><br>\n",
    "<center>$\\textrm{Cost}(h_{\\theta}(x),y)= -y\\log(h_{\\theta}(x))-(1-y)\\log(1-h_{\\theta}(x))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "giving:\n",
    "\n",
    "<center>$J(\\theta) = -\\frac{1}{2m}{\\sum^{m}_{i=1}}y\\log(h_{\\theta}(x))+(1-y)\\log(1-h_{\\theta}(x))$</center> <br>\n",
    "\n",
    "and adding a regularization term we have: <br><br>\n",
    "\n",
    "<center>$J(\\theta) = [\\frac{1}{m}{\\sum^{m}_{i=1}}-y^{(i)}\\log(h_{\\theta}(x^{(i)})) - (1-y^{(i)})\\log(1-h_{\\theta}(x^{(i)}))] + \\frac{\\lambda}{2m}\\sum^{n}_{j=1}\\theta_{j}^{2}  $</center> \n",
    "\n",
    "<br>\n",
    "\n",
    "where m is the number of training examples, and n is the number of parameters (where $\\theta_{0}$ is the parameter for the bias term). To find the parameters $\\theta$ that minimise our cost function we will use Gradient Descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent\n",
    "Recall that the general Gradient Descent algorithm is as follows:\n",
    "\n",
    "Repeat $\\{$\n",
    "\n",
    "<center>$\\theta_{j} := \\theta_{j}-\\alpha \\frac{\\delta}{\\delta \\theta_{j}}J(\\theta)$</center>\n",
    "\n",
    "$\\}$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Where the partial derivative of the regularized cost function<br>\n",
    "\n",
    "for j=0 (i.e., for the bias term): <br>\n",
    "\n",
    "<center>$  \\frac{\\delta J(\\theta)}{\\delta \\theta_{j}} = \\frac{1}{m} {\\sum^{m}_{i=1}} (h_{\\theta}(x^{(i)} - y^{(i)})x_{j}^{(i)})        $<center>\n",
    "\n",
    "<br>\n",
    "    \n",
    "and for j $\\ge$ 1 (i.e. for the rest of the features): <br><br>\n",
    "    \n",
    "<center>$  \\frac{\\delta J(\\theta)}{\\delta \\theta_{j}} = \\frac{1}{m} {\\sum^{m}_{i=1}} (h_{\\theta}(x^{(i)} - y^{(i)})x_{j}^{(i)})) + \\frac{\\lambda}{m}\\theta_{j}        $<center><br><br>\n",
    "    \n",
    " \n",
    "Note: When implementing Gradient Descent, using a vectorised method (lineaavoids the need to create for loops. Gradient Descent can be rewritten as follows:<br><br>\n",
    "\n",
    "<center>$\\theta := \\theta -\\frac{\\alpha}{m} X^{T}(g(X\\theta)-\\bar{y}$</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the class\n",
    "\n",
    "After optimizing our parameters, $\\theta$, by gradient descent, we now want to predict the class labels. This is done by selecting a threshold.\n",
    "\n",
    "I.e.: <br>\n",
    "if $hyp_{\\theta}(x^{(i)}) \\ge 0.5, y_{pred}=1$ <br>\n",
    "if $hyp_{\\theta}(x^{(i)}) < 0.5, y_{pred}=0$ <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
